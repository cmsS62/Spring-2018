---
layout: post
published: true
category: commentary
title: Junger Assignment 4
author: Ashley junger
tags:
  - Digital_Humanities
---
## Junger Assignment 4

Volant online analysis tool:

This tool is very easy to use. You just copy and past your text, and it gives you five different analyses based off of the words. The first box has three options, one is a word cloud and another is a chart linking words. Both of those I didn’t find helpful at all- word clouds in general seem useless to me. But it did have a function where you can see the most used words, and how many times they’re used. Then you can select those terms and see how frequently they’re used in each segment of the play (although, I’m not quite sure what a segment is- I guess just tenths of the play). I chose to analyze the text from “A Midsummers Night’s Dream.” The most frequently used word in that text was love, and it had a huge spike in the 6th segment of the play, while the other top ten words appear to be down. There’s also a box where it displays the full text and tells you the frequency of each word. A box where it gives a summary of the text and frequency of phrases used. The last box tells you what is said before and after a word (context), bubble lines, and correlations. The last box is my favorite- I’m not sure how I’d use the correlation function, as analyzing word use that way would take a long time for high frequency words, but I think it’s neat. This gives me a pretty basic understanding of the text the most frequent words are love, shall, come, sweet, night. Love has a huge spike in the middle of the play, with the other top words staying pretty consistent. 

Most of the analysis has to do with the frequency of words which words are related. One thing that could be interesting is if they had an option to sort the word frequencies and relationships by the character who says them. That way you could analyze if there are differences in the way words are talked about between characters, or if one character is more focused on something than another one. It would also be interesting if the program could group related words like names, time of day, feelings, places, etc. to see if there were themes in what is talked about. This text can’t pick out similes, metaphors, or jokes, so much of the tone and meaning behind many words isn’t captured in these analyses. 

Alien Reading: Text Mining, Language Standardization, and the Humanities:

In this reading Binder examines text mining and how it affects humanities research today. In Binder’s view topic modeling takes literary analysis beyond what humans can do- people cannot (I guess they could but they don’t) go through a text and count the frequency of each word. The type of analysis these computer models generate are entirely different from the way humans have traditionally analyzed texts. Because these analyses have to be programed, there are underlying biases and assumptions inherent in any analytical result. Computers aren’t good at picking up on sarcasm, innuendo, metaphors, etc- computers are literal so the end up missing a lot of subtextual meaning, especially in works like poetry. While there are problems inherent in text-mining, it’s already widely in use. It’s a feature of search engines, spellcheck, and autocomplete. There isn’t really a way to exclude these biased programs from your research because they are already engraved into the way we interact with materials online. Binder’s solution to this inescapable programing is to recognize its alien-ness. He says we need “a renewed sense of the strangeness of the idea that words can be understood through the manipulation of numbers.” Acknowledging the models these programs were built off of, the biases used in their analysis of words, and their limitations will allow scholars to utilize these programs without internalizing their biases.

The part of the text I found most interesting/ surprising was when Binder suggested that 
we should employ these programs as “jokes.” I understand that viewing them as jokes ensures that their shortcomings are not incorporated into serious research; however, that seemed like a very limited solution. Only people with backgrounds in the humanities  and in algorithms would be in on the joke, and, as Binder pointed out, these types of programs are inescapable. While this suggestion would work for textual scholars conducting analyses, I don’t think this works as a broad suggestion for how to counteract these biases. In order to eliminate these biases, more work will have to be done to make training texts diverse and representative, and to ensure that word associations are accurate. That way everyone who uses these types of programs (which is everyone) can do so without internalizing different systematic biases.
