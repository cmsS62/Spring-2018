---
layout: post
published: true
category: commentary
title: Kavya's Week 4 Assignment
author: Kavya Ravichandran
---
(sorry this is late!)
## Text Analysis

Last week, when using the Folger API, I tried to find the most common words used in Hamlet that were somewhat unique to it (that is, not that commonly used today). 

I put Hamlet into Voyant, and I was intrigued to find that their word cloud listed a very similar set of words. Likewise, the word graph on the right mapped the frequency of these words throughout the play. I downloaded the words comprising the word cloud and compared it to my list of most common words, and I found that if I’d expanded my list of common words, I probably could’ve gotten an almost exact correlation. With that said, Voyant didn’t pick up “thou” and “thy,” where my filtering did. I think in addition to frequency, Voyant might have filtered for how generic a word might be. Including statistics about co-occurrences was helpful in understanding a bit about the characters (e.g., “lord” appeared with “Hamlet,” which means that Hamlet was a lord!) Overall, however, I don’t think Voyant helped me understand what a text was about, since the statistics seemed to be general. 

I also put it into Jstor’s text analyzer, which proved more useful in actually understand the themes of the work, based on the themes listed on the left. In addition, linking the text produced to papers and articles that were related help enrich access to the scholarship related to the text in question.

In terms of actually understanding a text via one of these resources, I think more advanced NLP would be useful in terms of summarizing/highlighting the important ideas.

## Reading

Language detection and interpretation
I thought one of the really important points brought up in the reading was the fact that different texts have different levels of representation. In particular, the reading brought up the vernacular used by African American characters in older texts. In general, in the context of discussing machine learning technology, there is a lot of conversation about biased datasets, and I think literature is a strong example of this, given that much of literature maintained as canonical classics were written by British and American white men. As a result, topic modeling could suffer from inherent limitations in terms of what topics occur often enough, and less-frequent but important topics may be marginalized.
